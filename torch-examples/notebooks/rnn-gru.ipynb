{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network (RNN) with Torch\n",
    "\n",
    "Simple tutorial to train your first RNN with torch. More specifically, we will train a Gated Reccurrent Unit (GRU) network.\n",
    "\n",
    "As a toy dataset, we will use the common MNIST dataset. More information about MNIST can be found at http://yann.lecun.com/exdb/mnist/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some dependecies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'rnn'\n",
    "require 'optim'\n",
    "mnist = require 'mnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load and shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = mnist.traindataset()\n",
    "test_data = mnist.testdataset()\n",
    "\n",
    "perm = torch.randperm(train_data.label:size(1)):long()\n",
    "train_data.data = train_data.data:index(1, perm):float()\n",
    "train_data.label = train_data.label:index(1, perm)\n",
    "\n",
    "test_data.data = test_data.data:float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some hyperparameters of the network.\n",
    "\n",
    "RNNs are designed to handle time sequences.\n",
    "\n",
    "Here, the images have a 28x28 shape, and we will consider them as a sequence of 28 time steps, each time step being a 28-dimensional vector. The network will look at images one column at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputSize = train_data.data:size(3) -- length of the input\n",
    "rho = 100000\n",
    "dropout = .2 -- each hidden neuron will be dropped with this given probability\n",
    "hiddenSize = 1024 -- number of hidden units of the GRU cell, also equals to the output size of the GRU\n",
    "classes_n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the network and print the network's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function create_model()\n",
    "    model = nn.Sequential()\n",
    "    model:add(nn.SplitTable(1,2))\n",
    "    -- model:add(nn.Sequencer(nn.GRU(inputSize, hiddenSize, rho, dropout)))\n",
    "    model:add(nn.Sequencer(nn.LSTM(inputSize, hiddenSize)))\n",
    "    model:add(nn.SelectTable(-1)) -- last step of output sequence\n",
    "    model:add(nn.Linear(hiddenSize, classes_n))\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> output]\n",
       "  (1): nn.SplitTable\n",
       "  (2): nn.Sequencer @ nn.LSTM(28 -> 1024)\n",
       "  (3): nn.SelectTable(-1)\n",
       "  (4): nn.Linear(1024 -> 10)\n",
       "}\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "print(model:__tostring())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the loss function. Here, we chose the common cross entropy loss that is suitable for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyCriterion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add one to the labels because the function `nn.CrossEntropyCriterion` expects classes starting from 1 and not 0. Thus, the class number 1 corresponds to the digit 0, ..., the class number 10 corresponds to the digit 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.label = (train_data.label + 1.0):float()\n",
    "test_data.label = (test_data.label + 1.0):float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining now hyperparameters related to the network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimState = {learningRate=0.01, momentum=0.5} -- parameters for the (minibatch) gradient descent algorithm\n",
    "\n",
    "batchSize = 128\n",
    "maxEpoch = 20\n",
    "\n",
    "display_n = 500000 -- display training loss and accuracy every x step\n",
    "test_n = 500 -- test the model every x step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- placeholder for mini-batch batch\n",
    "X_batch = train_data.data[{{1, batchSize}}]:clone():float()\n",
    "Y_batch = train_data.label[{{1, batchSize}}]:clone():float()\n",
    "\n",
    "-- placeholder for batch indices\n",
    "batchIndices = torch.LongTensor(batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can cast the model created as well as the different variables on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "cutorch.setDevice(3) -- chose which GPU to use\n",
    "model = model:cuda()\n",
    "criterion = criterion:cuda()\n",
    "train_data.data = train_data.data:cuda()\n",
    "test_data.data = test_data.data:cuda()\n",
    "X_batch = X_batch:cuda()\n",
    "Y_batch = Y_batch:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that returns the accuracy of a batch of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function get_accuracy(output_, y_true)\n",
    "    --- output_: a `Tensor`, output from the model.\n",
    "    --- y_true: labels\n",
    "    --- Returns accuracy\n",
    "    y_true = y_true:double()\n",
    "    _, y_predicted = torch.max(output_, 2)\n",
    "    y_predicted = y_predicted:double()\n",
    "    accuracy = y_true:eq(y_predicted):sum() / y_true:size(1)\n",
    "    return accuracy, y_predicted\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEST – epoch 0.00, loss: 2.8839, accuracy: 0.2114\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 1.07, loss: 0.2373, accuracy: 0.9172\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 2.14, loss: 0.2161, accuracy: 0.9286\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 3.20, loss: 0.2019, accuracy: 0.9371\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 4.27, loss: 0.2028, accuracy: 0.9414\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 5.34, loss: 0.2098, accuracy: 0.9420\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 6.40, loss: 0.2170, accuracy: 0.9427\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 7.47, loss: 0.2233, accuracy: 0.9457\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 8.54, loss: 0.2309, accuracy: 0.9441\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 9.60, loss: 0.2460, accuracy: 0.9432\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 10.67, loss: 0.2557, accuracy: 0.9433\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 11.74, loss: 0.2603, accuracy: 0.9433\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 12.80, loss: 0.2640, accuracy: 0.9450\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 13.87, loss: 0.2721, accuracy: 0.9437\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 14.94, loss: 0.2756, accuracy: 0.9443\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 16.00, loss: 0.2802, accuracy: 0.9440\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 17.07, loss: 0.2842, accuracy: 0.9439\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 18.14, loss: 0.2870, accuracy: 0.9434\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 19.20, loss: 0.2910, accuracy: 0.9441\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 20.00, loss: 0.2932, accuracy: 0.9436\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 20.00, loss: 0.2933, accuracy: 0.9436\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- model parameters for optimization\n",
    "local params, gradParams = model:getParameters()\n",
    "local iteration = 0\n",
    "\n",
    "local steps_per_epoch = train_data.label:size(1) / batchSize\n",
    "\n",
    "while true do\n",
    "   iteration = iteration + 1\n",
    "    \n",
    "   batchIndices:random(1, train_data.label:size(1))\n",
    "   X_batch:copy(train_data.data:index(1, batchIndices))\n",
    "   Y_batch:copy(train_data.label:index(1, batchIndices))\n",
    "\n",
    "    ----------------------------------------\n",
    "    -------------- TRAINING ----------------\n",
    "    ----------------------------------------\n",
    "   function feval(params)\n",
    "      gradParams:zero()\n",
    "      outputs = model:forward(X_batch)\n",
    "      loss = criterion:forward(outputs, Y_batch)\n",
    "      local gradOutputs = criterion:backward(outputs, Y_batch)\n",
    "      model:backward(X_batch, gradOutputs)\n",
    "      return loss, gradParams\n",
    "   end\n",
    "    \n",
    "   timer = torch.Timer() -- timer\n",
    "   optim.adagrad(feval, params, optimState)\n",
    "   datum_sec = batchSize / \n",
    "   timer:time().real\n",
    "    \n",
    "   if iteration % display_n == 0 then\n",
    "          print(string.format(\"TRAINING – epoch %.2f, loss = %.4f, %.2f datum/sec\", iteration / steps_per_epoch, loss, datum_sec))\n",
    "   end\n",
    "    ----------------------------------------\n",
    "    ----------------------------------------\n",
    "    \n",
    "    \n",
    "    ----------------------------------------\n",
    "    ------------- EVALUATION ---------------\n",
    "    ----------------------------------------\n",
    "   if (iteration - 1) % test_n == 0 or iteration / steps_per_epoch >= maxEpoch then\n",
    "       model:evaluate() -- evaluation mode, i.e. do not use dropout\n",
    "       local outputs_ = model:forward(test_data.data)\n",
    "       local loss_ = criterion:forward(outputs, test_data.label)\n",
    "       local accuracy, y_predicted = get_accuracy(outputs_, test_data.label)\n",
    "       print(string.format('TEST – epoch %.2f, loss: %.4f, accuracy: %.4f', iteration / steps_per_epoch, loss_, accuracy))\n",
    "       model:training() -- training mode, i.e. use dropout\n",
    "   end\n",
    "    ----------------------------------------\n",
    "    ----------------------------------------\n",
    "    \n",
    "    if iteration / steps_per_epoch > maxEpoch then\n",
    "        break\n",
    "   end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
