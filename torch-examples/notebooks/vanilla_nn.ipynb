{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch tutorial\n",
    "\n",
    "Simple tutorial to train your first neural network with torch.\n",
    "\n",
    "As a toy dataset, we will use the common MNIST dataset. More information about MNIST can be found at http://yann.lecun.com/exdb/mnist/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some dependecies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "mnist = require 'mnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = mnist.traindataset()\n",
    "test_data = mnist.testdataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the neural network architecture. It consists in a simple feedforward neural network with dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function create_model()\n",
    "    model = nn.Sequential()\n",
    "    model:add(nn.Reshape(28*28)) -- Reshape the images (1, 28, 28), i.e. grayscale 28x28 images. The batch\n",
    "    model:add(nn.Linear(28*28, 1024))\n",
    "    model:add(nn.Dropout(.5))\n",
    "    model:add(nn.ReLU())\n",
    "    model:add(nn.Linear(1024, 1024))\n",
    "    model:add(nn.Dropout(.5))\n",
    "    model:add(nn.ReLU())\n",
    "    model:add(nn.Linear(1024, 512))\n",
    "    model:add(nn.Dropout(.5))\n",
    "    model:add(nn.ReLU())\n",
    "    model:add(nn.Linear(512, 10))\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> output]\n",
       "  (1): nn.Reshape(784)\n",
       "  (2): nn.Linear(784 -> 1024)\n",
       "  (3): nn.Dropout(0.500000)\n",
       "  (4): nn.ReLU\n",
       "  (5): nn.Linear(1024 -> 1024)\n",
       "  (6): nn.Dropout(0.500000)\n",
       "  (7): nn.ReLU\n",
       "  (8): nn.Linear(1024 -> 512)\n",
       "  (9): nn.Dropout(0.500000)\n",
       "  (10): nn.ReLU\n",
       "  (11): nn.Linear(512 -> 10)\n",
       "}\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "print(model:__tostring())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the loss function. Here, we chose the common cross entropy loss that is suitable for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyCriterion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add one to the labels because the function `nn.CrossEntropyCriterion` expects classes starting from 1 and not 0. Thus, the class number 1 corresponds to the digit 0, ..., the class number 10 corresponds to the digit 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.label = (test_data.label +1.0):float()\n",
    "train_data.label = (train_data.label + 1.0):float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We define some hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimState = {learningRate=learningRate_, momentum=0.5} -- parameters for the (minibatch) gradient descent algorithm\n",
    "\n",
    "batchSize = 128\n",
    "maxEpoch = 20\n",
    "\n",
    "display_n = 500000 -- display training loss and accuracy every x step\n",
    "test_n = 500 -- test the model every x step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- placeholder for mini-batch\n",
    "X_batch = train_data.data[{{1, batchSize}}]:clone():float() -- variable that will hold the mini batch data\n",
    "Y_batch = train_data.label[{{1, batchSize}}]:clone():float() -- and the mini batch labels\n",
    "\n",
    "batchIndices = torch.LongTensor(batchSize) -- placeholder for batch indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can cast the model created as well as the different variables on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "cutorch.setDevice(1) -- chose which GPU to use\n",
    "model = model:cuda()\n",
    "criterion = criterion:cuda()\n",
    "train_data.data = train_data.data:cuda()\n",
    "test_data.data = test_data.data:cuda()\n",
    "X_batch = X_batch:cuda()\n",
    "Y_batch = Y_batch:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that returns the accuracy of a batch of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function get_accuracy(output_, y_true)\n",
    "    --- output_: a `Tensor`, output from the model.\n",
    "    --- y_true: labels\n",
    "    --- Returns accuracy\n",
    "    y_true = y_true:double()\n",
    "    _, y_predicted = torch.max(output_, 2)\n",
    "    y_predicted = y_predicted:double()\n",
    "    accuracy = y_true:eq(y_predicted):sum() / y_true:size(1)\n",
    "    return accuracy\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEST – epoch 0.00, accuracy: 0.0980\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 1.07, accuracy: 0.9429\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 2.14, accuracy: 0.9572\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 3.20, accuracy: 0.9621\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 4.27, accuracy: 0.9642\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 5.34, accuracy: 0.9672\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 6.40, accuracy: 0.9685\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 7.47, accuracy: 0.9704\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 8.54, accuracy: 0.9709\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 9.60, accuracy: 0.9738\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 10.67, accuracy: 0.9745\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 11.74, accuracy: 0.9734\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 12.80, accuracy: 0.9756\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 13.87, accuracy: 0.9748\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 14.94, accuracy: 0.9767\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 16.00, accuracy: 0.9771\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 17.07, accuracy: 0.9769\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 18.14, accuracy: 0.9774\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TEST – epoch 19.20, accuracy: 0.9776\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- model parameters for optimization\n",
    "local params, gradParams = model:getParameters()\n",
    "local iteration = 0\n",
    "local steps_per_epoch = data_train.label:size(1) / batchSize\n",
    "\n",
    "while true do\n",
    "   iteration = iteration + 1\n",
    "    \n",
    "   -- Take a random mini batch of data\n",
    "   batchIndices:random(1, train_data.data:size(1))\n",
    "   X_batch:copy(train_data.data:index(1, batchIndices))\n",
    "   Y_batch:copy(train_data.label:index(1, batchIndices))\n",
    "    \n",
    "   -- when maxEpoch is reached, end the optimization\n",
    "   if iteration / steps_per_epoch > maxEpoch then\n",
    "        break\n",
    "   end\n",
    " \n",
    "    ----------------------------------------\n",
    "    -------------- TRAINING ----------------\n",
    "    ----------------------------------------\n",
    "   function feval(params)\n",
    "      gradParams:zero()\n",
    "      outputs = model:forward(X_batch)\n",
    "      loss = criterion:forward(outputs, Y_batch)\n",
    "      local gradOutputs = criterion:backward(outputs, Y_batch)\n",
    "      model:backward(X_batch, gradOutputs)\n",
    "      return loss, gradParams\n",
    "   end\n",
    "    \n",
    "   timer = torch.Timer() -- timer\n",
    "   optim.adagrad(feval, params, optimState) -- perform one training step\n",
    "   datum_sec = batchSize / timer:time().real -- measure the time for one training step\n",
    "    \n",
    "   if iteration % display_n == 0 then\n",
    "          print(string.format(\"TRAINING – epoch %.2f, loss = %f, %.2f datum/sec\", iteration / steps_per_epoch, loss, datum_sec))\n",
    "   end\n",
    "    ----------------------------------------\n",
    "    ----------------------------------------\n",
    "    \n",
    "    \n",
    "    ----------------------------------------\n",
    "    ------------- EVALUATION ---------------\n",
    "    ----------------------------------------\n",
    "   if (iteration - 1) % test_n == 0 or iteration / steps_per_epoch >= maxEpoch then\n",
    "        model:evaluate() -- evaluation mode. This is important to disable the dropout while testing the model\n",
    "        local outputs_ = model:forward(test_data.data)\n",
    "        local accuracy = get_accuracy(outputs_, test_data.label)\n",
    "        print(string.format('TEST – epoch %.2f, accuracy: %.4f', iteration / steps_per_epoch, accuracy))\n",
    "        model:training() -- reactivate dropout\n",
    "   end\n",
    "    ----------------------------------------\n",
    "    ----------------------------------------\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
