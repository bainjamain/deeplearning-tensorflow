{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One shot learning (UNFINISHED).\n",
    "\n",
    "Imagine we have a bunch of classes, say 10 classes, and we'd like to perform a classification task. However, we only have a good amount of data for 8 classes out of 10. For the other 2 classes, there's only a very limited number of examples (say 1 or 2 examples for instance). The idea of *one shot learning* is to train a network on the classes for which we have a lot of data and use this trained network to classify examples from the classes for which it wasn't trained on. Here, we mostly follow the approach described in *Siamese Neural Networks for One-shot Image Recognition* by Koch et al.\n",
    "\n",
    "We use a siamese architecture that we train on the MNIST data set. More specifically, we only train the netowk on digits from 0 to 7. The network will take two images and answer the following question: **do the two inputs belong to the same class?** After the training has been completed, we try to classify the digits 8 and 9 by comparing the testing examples to the very limited labeled data we have for these classes.\n",
    "\n",
    "For more details on *siamese architecture*, we refer the interested reader to the implementation of a siamese network in the notebook **siamese**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm # just for esthetics (progression bar)\n",
    "sys.path.insert(0, '../data_processing/')\n",
    "from siamese_data import MNIST # load the data and process it\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = MNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning a similarity metric with a siamese network\n",
    "\n",
    "We are going to implement a siamese architecture similar to the one described in the **siamese notebook**, but with a stacked bi-directional LSTM network instead of a vanilla bi-directional LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first fix the hyperparameters for:\n",
    "- The training:\n",
    "    - Number of iterations,\n",
    "    - Learning rate,\n",
    "    - Batch size.\n",
    "- The network architectures:\n",
    "    - Number of stacked LSTMs,\n",
    "    - Number of neurons of each LSTM cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iter = 15000 # maximum number of iterations for training\n",
    "learning_rate = 0.001\n",
    "batch_train = 128 # batch size for training\n",
    "batch_test = 512 # batch size for testing\n",
    "display = 10 # display the training loss and accuracy every `display` step\n",
    "n_test = 20 # how frequently to test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 # dimension of each of the input vectors\n",
    "n_steps = 28 # sequence length\n",
    "n_hidden = [128, 64, 64] # number of neurons of each of the LSTM cell.\n",
    "n_classes = 2 # two possible classes, either `same` of `different`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    x1 = tf.placeholder(tf.float32, shape=[None, n_steps, n_inputs]) # placeholder for the first network (image 1)\n",
    "    x2 = tf.placeholder(tf.float32, shape=[None, n_steps, n_inputs]) # placeholder for the second network (image 2)\n",
    "\n",
    "    # placeholder for the label. `1` for `same` and `0` for `different`.\n",
    "    y = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "    # placeholder for dropout (we could use different dropout for different part of the architecture)\n",
    "    keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_input(x_):\n",
    "    \"\"\"\n",
    "    Reshape the inputs to match the shape requirements of the function\n",
    "    `tf.nn.bidirectional_rnn`\n",
    "    \n",
    "    Args:\n",
    "        x_: a tensor of shape `(batch_size, n_steps, n_inputs)`\n",
    "        \n",
    "    Returns: a `list` of length `n_steps` with its elements being tensors\n",
    "    of shape `(batch_size, n_inputs)`\n",
    "    \"\"\"\n",
    "    x_ = tf.transpose(x_, [1, 0, 2]) # shape: (n_steps, batch_size, n_inputs)\n",
    "    x_ = tf.split(0, n_steps, x_) # a list of `n_steps` tensors of shape (1, batch_size, n_steps)\n",
    "    return [tf.squeeze(z, [0]) for z in x_] # remove size 1 dimension --> (batch_size, n_steps)\n",
    "\n",
    "\n",
    "x1_, x2_ = reshape_input(x1), reshape_input(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(x_):\n",
    "    \"\"\"\n",
    "    Defines the network.\n",
    "    \n",
    "    Args:\n",
    "        x_: a tensor of shape `(batch_size, n_steps, n_inputs)` containing a batch\n",
    "            of images that will be fed to one of the two networks.\n",
    "    \n",
    "    Returns the last states from the forward and backward cell.\n",
    "    \"\"\"    \n",
    "    lstm_cells_fw = []\n",
    "    lstm_cells_bw = []\n",
    "    for hid_units in n_hidden:\n",
    "        lstm_cells_fw.append(tf.nn.rnn_cell.BasicLSTMCell(hid_units, forget_bias=1.0, state_is_tuple=True))\n",
    "        lstm_cells_bw.append(tf.nn.rnn_cell.BasicLSTMCell(hid_units, forget_bias=1.0, state_is_tuple=True))\n",
    "    stacked_lstm_fw = tf.nn.rnn_cell.MultiRNNCell(lstm_cells_fw, state_is_tuple=True)\n",
    "    stacked_lstm_bw = tf.nn.rnn_cell.MultiRNNCell(lstm_cells_bw, state_is_tuple=True)\n",
    "    \n",
    "    stacked_lstm_fw = tf.nn.rnn_cell.DropoutWrapper(stacked_lstm_fw, output_keep_prob=keep_prob)\n",
    "    stacked_lstm_bw = tf.nn.rnn_cell.DropoutWrapper(stacked_lstm_bw, output_keep_prob=keep_prob)\n",
    "    \n",
    "    \n",
    "    _, last_state_fw, last_state_bw = tf.nn.bidirectional_rnn(\n",
    "                                        stacked_lstm_fw, stacked_lstm_bw, x_,\n",
    "                                        dtype=tf.float32)\n",
    "    return last_state_fw, last_state_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    with tf.variable_scope('siamese_network') as scope:\n",
    "        with tf.name_scope('network_1'):\n",
    "            last_state_fw1, last_state_bw1 = net(x1_)\n",
    "        with tf.name_scope('network_2'):\n",
    "            scope.reuse_variables() # tied weights (reuse the weights from `network_1` for `network_2`)\n",
    "            last_state_fw2, last_state_bw2 = net(x2_)\n",
    "\n",
    "    last_state1 = []\n",
    "    last_state2 = []\n",
    "    for i in range(len(n_hidden)):\n",
    "        for j in range(2):\n",
    "            last_state1.extend([last_state_bw1[i][j], last_state_fw1[i][j]])\n",
    "            last_state2.extend([last_state_bw2[i][j], last_state_fw2[i][j]])\n",
    "\n",
    "    last_state1 = tf.concat(1, last_state1) # We concatenate the states of the first network\n",
    "    last_state2 = tf.concat(1, last_state2) # We concatenate the states of the second network\n",
    "\n",
    "    # Weights and biases for the layer that connects the outputs from the two networks\n",
    "    weights = tf.get_variable('weigths_out', shape=[4 * np.sum(n_hidden), n_classes],\n",
    "                    initializer=tf.random_normal_initializer(stddev=1.0/float(np.sum(n_hidden))))\n",
    "    biases = tf.get_variable('biases_out', shape=[n_classes])\n",
    "\n",
    "    # difference between the states from the two networks\n",
    "    last_states_diff = tf.abs(last_state1 - last_state2) \n",
    "    logits = tf.matmul(last_states_diff, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), y) \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_snapshot = 1000 # save the weights every `n_snapshot` step\n",
    "checkpoint_dir = '../models/one_shot_learning/'\n",
    "saver = tf.train.Saver() # to save the trained model and, later, to restore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# the argument `allow_soft_placement=True` indicates that if a given function is\n",
    "# not implemented for GPUs, tensorflow will automatically use its CPU counterpart.\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    sess.run(init) # initialize all variables\n",
    "    print('Network training begins.')\n",
    "    for i in range(1, max_iter + 1):\n",
    "        start = time.time()\n",
    "        # We retrieve a batch of data from the training set\n",
    "        batch_x1, batch_x2, batch_y = data.get_next_batch(batch_train, phase='train', one_shot=True)\n",
    "        # We feed the data to the network for training\n",
    "        feed_dict = {x1: batch_x1, x2: batch_x2, y: batch_y, keep_prob: .75}\n",
    "        _, loss_, accuracy_ = sess.run([optimizer, loss, accuracy], feed_dict=feed_dict)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        if i % display == 0:\n",
    "            print('step %i, training loss: %.5f, training accuracy: %.3f, %.3f datum/sec' % (\n",
    "                    i, loss_, accuracy_, elapsed / batch_train))\n",
    "        \n",
    "        # Testing the network\n",
    "        if i % n_test == 0:\n",
    "            # Retrieving data from the test set\n",
    "            batch_x1, batch_x2, batch_y = data.get_next_batch(batch_test, phase='test', one_shot=True)\n",
    "            feed_dict = {x1: batch_x1, x2: batch_x2, y: batch_y, keep_prob: 1.0}\n",
    "            accuracy_test = sess.run(accuracy, feed_dict=feed_dict)\n",
    "            print('testing step %i, accuracy %.3f' % (i, accuracy_test))\n",
    "            \n",
    "            \n",
    "        # We save a snapshot of the weights\n",
    "        if i % n_snapshot == 0:\n",
    "            save_path = saver.save(sess, os.path.join(checkpoint_dir,'snapshot_') + str(i) + '.ckpt')\n",
    "            print('Snapshot saved in file: %s' % save_path)\n",
    "            \n",
    "    print('********************************')\n",
    "    print('Training finished.')\n",
    "    \n",
    "    # testing the trained network on a large sample\n",
    "    batch_x1, batch_x2, batch_y = data.get_next_batch(10000, phase='test', one_shot=True)\n",
    "    feed_dict = {x1: batch_x1, x2: batch_x2, y: batch_y, keep_prob:1.0}\n",
    "    accuracy_test = sess.run(accuracy, feed_dict=feed_dict)\n",
    "    print('********************************')\n",
    "    print('Testing the network.')\n",
    "    print('Network accuracy %.3f' % (accuracy_test))\n",
    "    print('********************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One shot learning: using the pretrained similarity metric on new classes\n",
    "\n",
    "We now want to see how the network performs on images from unseen classes, i.e. eights and nines.\n",
    "\n",
    "Following the approach described by Koch et al., we chose 10 images ($i_0, i_1,...,i_9$), one per class. We then classify an image by comparing it pairwise with the images $i_0,...,i_9$.\n",
    "\n",
    "But first, let's chose 10 reference images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_example_per_class = []\n",
    "for digit in data.digits:\n",
    "    one_example_per_class.append(\n",
    "        getattr(data, digit + '_train')[\n",
    "            np.random.randint(len(getattr(data, digit + '_train')))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we display the 10 images we use ($i_0,...,i_9$) as a benchmark for pairwise comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,2))\n",
    "for i in range(1, 11):\n",
    "    a = fig.add_subplot(2, 5, i)\n",
    "    a.axis('off')\n",
    "    image = one_example_per_class[i - 1].reshape((28, 28)) # reshape the image from (784) to (28, 28).\n",
    "    a.imshow(image, cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve the model trained above, and we classify images of 8 and 9 by comparing them with the benchmark images $i_0,...,i_9$. We report the accuracy of the classifcation on the *seen* and *unseen* classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reshape_input(image):\n",
    "    \"\"\"\n",
    "    Reshapes an image from `(784)` to `(1, 28, 28)`.\n",
    "    \n",
    "    Args:\n",
    "        image: a `numpy array` of shape `(784)`.\n",
    "    \n",
    "    Returns  a `numpy array` of shape `(1, 28, 28)`.\n",
    "    \"\"\"\n",
    "    image = np.expand_dims(image.reshape((28,28)), axis=0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_benchmark(images):\n",
    "    \"\"\"\n",
    "    Concatenates the 10 images of the benchmark into one tensor.\n",
    "    \n",
    "    Args:\n",
    "        images: a `list` of ten `numpy array`s of shape (784).\n",
    "    \n",
    "    Returns a `numpy array` of shape `(10, 28, 28)`.   \n",
    "    \"\"\"\n",
    "    images = [reshape_input(x) for x in images]\n",
    "    return np.concatenate(images)\n",
    "        \n",
    "\n",
    "def duplicate_input(image):\n",
    "    \"\"\"\n",
    "    Duplicates the image ten times.\n",
    "    \n",
    "    Args:\n",
    "        image: a `numpy array` of shape (784).\n",
    "    \n",
    "    Returns a `numpy array` of shape (10, 28, 28).\n",
    "    \"\"\"\n",
    "    image = reshape_input(image)\n",
    "    image = [image for x in range(10)]\n",
    "    return np.concatenate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prediction_bunch(predictions, bunch=32):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        predictions: a `numpy array` of shape `(10 * bunch, 2)`. The second\n",
    "            column contains the probability that the given inputs are similar.\n",
    "        bunch: an `integer` equal the to the batch size divided by 10.\n",
    "    \n",
    "    Returns a list of length `bunch` containing the predicted labels, i.e.\n",
    "    a list of integers between 0 and 9.\n",
    "    \"\"\"\n",
    "    predictions_ = []\n",
    "    for i in range(bunch):\n",
    "        predictions_.append(np.argmax(predictions[10 * i : 10 * (i + 1), 1]))\n",
    "    return predictions_\n",
    "\n",
    "def test_number(data_, benchmark, sess, bunch=32):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_: a `list` of `numpy array`s containing images from a specific class\n",
    "            (e.g. only 5 or only 9). The images have a shape `(784)`.\n",
    "        benchmark: a `numpy array` of shape `(10, 28, 28)`.\n",
    "        sess: a tensorflow session.\n",
    "        bunch: an `integer` equal the to the batch size divided by 10. It represents\n",
    "            the number of different images being fed to the network at the same time.\n",
    "    \n",
    "    Returns a list of length `bunch` containing the label predictions.\n",
    "    \"\"\"\n",
    "    benchmark_ = np.concatenate([benchmark for _ in range(bunch)])\n",
    "    y_pred = []\n",
    "    for i in range(0, len(data_) - bunch, bunch):\n",
    "        digit1 = np.concatenate([duplicate_input(data_[j]) for j in range(i, i + bunch)])\n",
    "    \n",
    "        prediction_prob = tf.nn.softmax(logits)\n",
    "        feed_dict = {x1: digit1, x2: benchmark_, keep_prob: 1.0}\n",
    "        prediction_prob = sess.run(prediction_prob, feed_dict=feed_dict)\n",
    "        y_pred.extend(prediction_bunch(prediction_prob, bunch))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digit_mapping  = {i: j for (i, j) in zip(data.digits, range(10))}\n",
    "benchmark = create_benchmark(one_example_per_class)\n",
    "\n",
    "bunch = 128 # number of different images to test at the same time (batch size = 10 * bunch)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir=checkpoint_dir)\n",
    "    saver.restore(sess, latest_checkpoint)\n",
    "    print('%s was restored.' % latest_checkpoint)\n",
    "    for i, j in digit_mapping.iteritems():\n",
    "        print i, j\n",
    "        y_pred = test_number(getattr(data, i + '_test'), benchmark, sess, bunch=bunch)\n",
    "        y_true = [j] * len(y_pred)\n",
    "        print 'Accuracy for %i is %.3f' % (j, accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(digit1_, pred):\n",
    "    fig = plt.figure(figsize=(7,2))\n",
    "    b = fig.add_subplot(2, 1, 1)\n",
    "    b.axis('off')\n",
    "    b.imshow(digit1_[0], cmap='Greys_r')\n",
    "    b = fig.add_subplot(2, 1, 2)\n",
    "    b.axis('off')\n",
    "    b.imshow(benchmark[pred], cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_results(duplicate_input(data.sevens_test[221]), 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
